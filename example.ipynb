{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee5b7c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  Benchmarking class-out-of-distribution performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e990c8f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this example we will see how to use our framework to benchmark C-OOD performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43747d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To use the dataset from our paper (a subset of ImageNet-21k), first download ImageNet-21k in its entirety and use the GetBenchmarkingDataset(path_to_ImageNet21k) to trasnform it into our filtered version of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c905d6c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83012f0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cood_uncertainty_lib import benchmark_model_on_cood_with_severities\n",
    "import plotly.express"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2e0a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using our framework to benchmark a model is as easy as using two lines of code:\n",
    "```\n",
    "    results = benchmark_model_on_cood_with_severities(model='resnet50')\n",
    "    plotly.express.line(results, x='severity_levels', y='cood-auroc', color='model_name-kappa')\n",
    "```\n",
    "\n",
    "The above code will benchmark a pretrained ResNet-50 available in the timm repo ( https://github.com/rwightman/pytorch-image-models ) on ImageNet and will plot its \"degradation graph\" (identical to Figure 1 from the paper).\n",
    "\n",
    "To save compute, in this example we will benchmark models on a smaller dummy dataset.\n",
    "To do that, we first need to define our custom dataset that consists of an ID component (in the complete dataset this component is made of classes from ImageNet-1k) and an OOD component (in the complete dataset this component is a filtered version of ImageNet-21k without the classes from ImageNet-1k):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0742fc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy dataset was already found in the given directory. Skipping its download.\n"
     ]
    }
   ],
   "source": [
    "from download_dummy_dataset import download_dummy_dataset\n",
    "download_dummy_dataset('../test_COOD2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fe9f8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# <path to images dir>/classname/*.(jpg|png|jpeg)\n",
    "dummy_ood_dataset_info = {\n",
    "    'dataset_name': 'Dummy_OOD',\n",
    "    'images_base_folder': '..\\test_COOD2\\dummy_ood',  \n",
    "    'test_estimation_split_percentage': 0.25\n",
    "}\n",
    "\n",
    "dummy_id_dataset_info = {\n",
    "    'dataset_name': 'Dummy_ID',\n",
    "    'images_base_folder': '..\\test_COOD2\\dummy_id',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82074350",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The 'dataset_name' value is used for the metadata for the dataset (##note to Mohammed: is this an important argument? why should the user care for it?)\n",
    "\n",
    "'test_estimation_split_percentage' defines the split between the amount of the OOD data used to estimate each class' severity (hardness) score and the amount used for testing its performance. For ImageNet, we used 25% for testing (50 samples) vs 75% for estimation (150 samples).\n",
    "\n",
    "Note that you can define your own custom datasets in a similar fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6e7c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's use our custom dummy dataset and evaluate a pretrained ResNet-18 model with softmax as its confidence function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f245ff47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'severity_levels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3982d72c1c74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                     \u001b[0mconfidence_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                     \u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_ood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                                     id_dataset_info=dummy_id_dataset_info)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'severity_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ood-auroc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_name-kappa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mmodel_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model_results_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{model_name}_{results_file_tag}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_results\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforce_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseverity_levels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevels_to_benchmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'severity_levels'"
     ]
    }
   ],
   "source": [
    "results = benchmark_model_on_cood_with_severities(model='resnet18',\n",
    "                                                    confidence_function='softmax',\n",
    "                                                    cood_dataset_info=dummy_ood_dataset_info,\n",
    "                                                    id_dataset_info=dummy_id_dataset_info)\n",
    "fig = plotly.express.line(results, x='severity_level', y='ood-auroc', color='model_name-kappa')\n",
    "fig.show('png')\n",
    "# Unfortunately, github doesn't load plotly plots on notebooks. This is why we show them as png files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec665d8f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The above plot is a 'degradation graph', showing the model's performance in AUROC (y axis) across different severity levels (x axis).\n",
    "\n",
    "Note that after running this code snippet, a new results csv was added at .\\models_results\\resnet18\\resnet18_softmax_n11.csv \n",
    "\n",
    "- The code first checks whether or not results for this specific combination of *(model, confidence function)* already exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d1483",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also evaluate and compare different models at the same time.\n",
    "For example, suppose we want to compare two models, ResNet-18 and ResNet-34, each equipped with either softmax or entropy as its confidence function.\n",
    "\n",
    "In this case, we can pass lists containing the models and lists containing the confidence functions (instead of just passing one string), as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "387a721f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'severity_levels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bfa22330cd4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                     \u001b[0mconfidence_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'entropy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                     \u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_ood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                                     id_dataset_info=dummy_id_dataset_info)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'severity_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ood-auroc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_name-kappa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    157\u001b[0m         return benchmark_list_inputs(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info,\n\u001b[0;32m    158\u001b[0m                                      \u001b[0mnum_severity_levels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels_to_benchmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                                      confidence_key)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msanity_check_confidence_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidence_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCONFIDENCE_METRIC_INPUT_ERR_MSG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_list_inputs\u001b[1;34m(models_list, confidence_metrics_list, *args)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mall_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence_metrics_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenchmark_model_on_cood_with_severities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mall_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mmodel_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model_results_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{model_name}_{results_file_tag}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_results\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforce_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseverity_levels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevels_to_benchmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'severity_levels'"
     ]
    }
   ],
   "source": [
    "results = benchmark_model_on_cood_with_severities(model=['resnet18', 'resnet34'],\n",
    "                                                    confidence_function=['softmax', 'entropy'],\n",
    "                                                    cood_dataset_info=dummy_ood_dataset_info,\n",
    "                                                    id_dataset_info=dummy_id_dataset_info)\n",
    "fig = plotly.express.line(results, x='severity_level', y='ood-auroc', color='model_name-kappa')\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b461c63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that since we've already evaluated ResNet-18 with a softmax confidence function before, the same results were used for this current comparison rather than being calculated again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4a270",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluating custom models and confidence functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7fcb0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Evaluating custom models:**\n",
    "There are a number of ways to pass the model to the *benchmark_model_on_cood_with_severities* method.\n",
    "- If it is a 'timm' model, its matching string name could be passed (as seen in the examples above).\n",
    "- Otherwise, the method expects a dictionary like the one in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac54b448",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:136: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  f\"Using {sequence_to_str(tuple(keyword_only_kwargs.keys()), separate_last='and ')} as positional \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset will have 33300 samples.\n",
      "Evaluating with softmax as a confidence function:   0%|                                        | 0/521 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Code\\COOD_benchmarking\\utils\\custom_dataset.py\", line 51, in __getitem__\n    img = self.transform(image_file)\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\_presets.py\", line 56, in forward\n    img = F.resize(img, self.resize_size, interpolation=self.interpolation)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 462, in resize\n    _, image_height, image_width = get_dimensions(img)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 75, in get_dimensions\n    return F_pil.get_dimensions(img)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py\", line 33, in get_dimensions\n    raise TypeError(f\"Unexpected type {type(img)}\")\nTypeError: Unexpected type <class 'str'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-518053e24a4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                                     \u001b[0mconfidence_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                                     \u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_ood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                                     id_dataset_info=dummy_id_dataset_info)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'severity_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ood-auroc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_name-kappa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    193\u001b[0m                                                           \u001b[0mnum_id_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_id_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                                                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m                                                           force_run=force_run, confidence_key=confidence_key)\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlevels_to_benchmark\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mget_cood_benchmarking_datasets\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, num_severity_levels, num_id_classes, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    108\u001b[0m                                                           \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                                                           \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfidence_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                                                           confidence_args=confidence_args)\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mtrain_ood_confidences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggregate_results_from_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mapply_model_function_on_dataset_samples\u001b[1;34m(rank, model, datasets, datasets_subsets, batch_size, num_workers, function, confidence_args)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mfunction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_confidence_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfidence_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\utils\\confidence_functions.py\u001b[0m in \u001b[0;36mextract_softmax_on_dataset\u001b[1;34m(model, data_loader, confidence_args, device)\u001b[0m\n\u001b[0;32m    443\u001b[0m         with tqdm.tqdm(desc=\"Evaluating with softmax as a confidence function\", total=num_batches,\n\u001b[0;32m    444\u001b[0m                        file=sys.stdout) as pbar:\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1331\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1333\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[1;31m# instantiate since we don't know how to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Code\\COOD_benchmarking\\utils\\custom_dataset.py\", line 51, in __getitem__\n    img = self.transform(image_file)\n  File \"C:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\_presets.py\", line 56, in forward\n    img = F.resize(img, self.resize_size, interpolation=self.interpolation)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 462, in resize\n    _, image_height, image_width = get_dimensions(img)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 75, in get_dimensions\n    return F_pil.get_dimensions(img)\n  File \"C:\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py\", line 33, in get_dimensions\n    raise TypeError(f\"Unexpected type {type(img)}\")\nTypeError: Unexpected type <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "from utils.misc import get_open_img_transforms, tvtf\n",
    "\n",
    "weights = MobileNet_V3_Small_Weights.DEFAULT\n",
    "transforms = weights.transforms()\n",
    "open_img_transforms = tvtf.Compose(\n",
    "        [get_open_img_transforms(), transforms])\n",
    "\n",
    "model = mobilenet_v3_small(weights)\n",
    "\n",
    "example_model_input = {'model_name': 'mobilenet_v3_small', 'model': model, 'transforms': transforms}\n",
    "results = benchmark_model_on_cood_with_severities(model=example_model_input,\n",
    "                                                    confidence_function='softmax',\n",
    "                                                    cood_dataset_info=dummy_ood_dataset_info,\n",
    "                                                    id_dataset_info=dummy_id_dataset_info)\n",
    "fig = plotly.express.line(results, x='severity_level', y='ood-auroc', color='model_name-kappa')\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a0cb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The *'model_name'* argument defines the name for the directory into which the results will be saved in ./models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f007848",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Evaluating custom confidence functions:**\n",
    "We've implemented the following confidence functions in utils/confidence_functions.py:\n",
    "- Softmax response\n",
    "- Entropy\n",
    "- Max logit\n",
    "- ODIN\n",
    "- MC Dropout\n",
    "\n",
    "Additional confidence functions could be defined and passed as an argument for *'benchmark_model_on_cood_with_severities'*. In the following code snippet we use *'extract_softmax_on_dataset'* as an example for a possible confidence function to be defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e45ba344",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "model needs to be either a string or nn.Module instance or a dictionary with keys 'model_name'(string) or 'nn.Module' (nn.Module)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e96ab683179b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                     \u001b[0mconfidence_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_confidence_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                     \u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_ood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                                     id_dataset_info=dummy_id_dataset_info)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'severity_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ood-auroc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_name-kappa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msanity_check_confidence_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidence_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCONFIDENCE_METRIC_INPUT_ERR_MSG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0msanity_model_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidence_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_INPUT_ERR_MSG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mconfidence_args_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs_dict_to_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidence_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: model needs to be either a string or nn.Module instance or a dictionary with keys 'model_name'(string) or 'nn.Module' (nn.Module)"
     ]
    }
   ],
   "source": [
    "from utils.confidence_functions import extract_softmax_on_dataset\n",
    "custom_confidence_function = {'confidence_metric_name': 'softmax_response', \n",
    "                              'confidence_metric_callable': extract_softmax_on_dataset}\n",
    "results = benchmark_model_on_cood_with_severities(model='resnet18',\n",
    "                                                    confidence_function=custom_confidence_function,\n",
    "                                                    cood_dataset_info=dummy_ood_dataset_info,\n",
    "                                                    id_dataset_info=dummy_id_dataset_info)\n",
    "fig = plotly.express.line(results, x='severity_level', y='ood-auroc', color='model_name-kappa')\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc7847",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Advanced tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c5d3b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Evaluating specific severity levels:** If we want to make a similar comparison but we're only interested in specific severity levels, for example, 8-10, we can pass the desired levels as an argument to the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567f2f64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'severity_levels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a890de33ae7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                     \u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_ood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                     \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_id_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                                     levels_to_benchmark=[8,9,10])\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'severity_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ood-auroc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_name-kappa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    157\u001b[0m         return benchmark_list_inputs(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info,\n\u001b[0;32m    158\u001b[0m                                      \u001b[0mnum_severity_levels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels_to_benchmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                                      confidence_key)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msanity_check_confidence_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidence_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCONFIDENCE_METRIC_INPUT_ERR_MSG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_list_inputs\u001b[1;34m(models_list, confidence_metrics_list, *args)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mall_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence_metrics_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenchmark_model_on_cood_with_severities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mall_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mmodel_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model_results_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{model_name}_{results_file_tag}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_results\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforce_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseverity_levels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevels_to_benchmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'severity_levels'"
     ]
    }
   ],
   "source": [
    "results = benchmark_model_on_cood_with_severities(model=['resnet18', 'resnet34'],\n",
    "                                                    confidence_function=['softmax', 'entropy'],\n",
    "                                                    cood_dataset_info=dummy_ood_dataset_info,\n",
    "                                                    id_dataset_info=dummy_id_dataset_info,\n",
    "                                                    levels_to_benchmark=[8,9,10])\n",
    "fig = plotly.express.line(results, x='severity_level', y='ood-auroc', color='model_name-kappa')\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aad5da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Evaluating a custom number of severity levels:**\n",
    "In the paper we have used 11 severity levels for analysis, but we can define less \\ more levels to be used. This is done using the 'num_severity_levels' argument: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c27dc89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'severity_levels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6c207dcc5d39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                     \u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_ood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                     \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_id_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                                     num_severity_levels=21)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'severity_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ood-auroc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_name-kappa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    157\u001b[0m         return benchmark_list_inputs(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info,\n\u001b[0;32m    158\u001b[0m                                      \u001b[0mnum_severity_levels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels_to_benchmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                                      confidence_key)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msanity_check_confidence_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidence_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCONFIDENCE_METRIC_INPUT_ERR_MSG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_list_inputs\u001b[1;34m(models_list, confidence_metrics_list, *args)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mall_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence_metrics_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenchmark_model_on_cood_with_severities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mall_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Code\\COOD_benchmarking\\cood_uncertainty_lib.py\u001b[0m in \u001b[0;36mbenchmark_model_on_cood_with_severities\u001b[1;34m(model, confidence_function, confidence_args, cood_dataset_info, id_dataset_info, num_severity_levels, levels_to_benchmark, batch_size, num_workers, rank, force_run, confidence_key)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mmodel_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model_results_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{model_name}_{results_file_tag}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_results\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforce_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseverity_levels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevels_to_benchmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcood_dataset_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_dataset_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'severity_levels'"
     ]
    }
   ],
   "source": [
    "results = benchmark_model_on_cood_with_severities(model=['resnet18', 'resnet34'],\n",
    "                                                    confidence_function=['softmax', 'entropy'],\n",
    "                                                    cood_dataset_info=dummy_ood_dataset_info,\n",
    "                                                    id_dataset_info=dummy_id_dataset_info,\n",
    "                                                    num_severity_levels=21)\n",
    "fig = plotly.express.line(results, x='severity_level', y='ood-auroc', color='model_name-kappa')\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5cac6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af80148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5eaaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
